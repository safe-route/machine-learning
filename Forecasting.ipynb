{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "840aa704-6ca0-4fe9-af7a-e0c1d0e889ff",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d371c76a-f6f5-4d71-82f4-df7888d8107a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# # Utils\n",
    "# from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9d61ec-65bf-4370-aef3-b443dacf8410",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b989cef0-7d2b-4442-b155-e829007420ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "learning_rate = 5e-2\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "loss = tf.keras.losses.Huber()\n",
    "metrics = [\"mae\", \"mse\"]\n",
    "epochs = 1000\n",
    "\n",
    "# Data split\n",
    "test_split = 0.1               # Float or int\n",
    "valid_split = 0.25             # Float\n",
    "train_split = 1 - valid_split  # Float\n",
    "\n",
    "# Dataset window\n",
    "steps_size = 40                     # minutes\n",
    "predicts_size = 1             # minute(s)\n",
    "window_size = steps_size + predicts_size\n",
    "batch_size = 32\n",
    "shuffle_buffer_size = 64\n",
    "\n",
    "# Dataset frame\n",
    "num_of_features = 6\n",
    "num_of_labels = 2\n",
    "\n",
    "# File\n",
    "dataset_file = './dataset/user_1/user_1_data.csv'\n",
    "model_1_file = './model/user_1/'\n",
    "model_2_file = './model/...'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8c65a6-31c7-4a6a-acaf-d061b6a43b73",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920ee007-c846-4910-919e-24935b1f5c34",
   "metadata": {},
   "source": [
    "## Fetching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b43bc0c-4536-4c9a-91e1-57d17bd259ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3/7/2022</td>\n",
       "      <td>0:00:00</td>\n",
       "      <td>-6.268917</td>\n",
       "      <td>106.780112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3/7/2022</td>\n",
       "      <td>0:01:00</td>\n",
       "      <td>-6.268917</td>\n",
       "      <td>106.780112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3/7/2022</td>\n",
       "      <td>0:02:00</td>\n",
       "      <td>-6.268917</td>\n",
       "      <td>106.780112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3/7/2022</td>\n",
       "      <td>0:03:00</td>\n",
       "      <td>-6.268917</td>\n",
       "      <td>106.780112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3/7/2022</td>\n",
       "      <td>0:04:00</td>\n",
       "      <td>-6.268917</td>\n",
       "      <td>106.780112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20155</th>\n",
       "      <td>3/20/2022</td>\n",
       "      <td>23:55:00</td>\n",
       "      <td>-6.268917</td>\n",
       "      <td>106.779552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20156</th>\n",
       "      <td>3/20/2022</td>\n",
       "      <td>23:56:00</td>\n",
       "      <td>-6.268917</td>\n",
       "      <td>106.779552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20157</th>\n",
       "      <td>3/20/2022</td>\n",
       "      <td>23:57:00</td>\n",
       "      <td>-6.268917</td>\n",
       "      <td>106.779552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20158</th>\n",
       "      <td>3/20/2022</td>\n",
       "      <td>23:58:00</td>\n",
       "      <td>-6.268917</td>\n",
       "      <td>106.779552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20159</th>\n",
       "      <td>3/20/2022</td>\n",
       "      <td>23:59:00</td>\n",
       "      <td>-6.268917</td>\n",
       "      <td>106.779552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20160 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date      time  latitude   longitude\n",
       "0       3/7/2022   0:00:00 -6.268917  106.780112\n",
       "1       3/7/2022   0:01:00 -6.268917  106.780112\n",
       "2       3/7/2022   0:02:00 -6.268917  106.780112\n",
       "3       3/7/2022   0:03:00 -6.268917  106.780112\n",
       "4       3/7/2022   0:04:00 -6.268917  106.780112\n",
       "...          ...       ...       ...         ...\n",
       "20155  3/20/2022  23:55:00 -6.268917  106.779552\n",
       "20156  3/20/2022  23:56:00 -6.268917  106.779552\n",
       "20157  3/20/2022  23:57:00 -6.268917  106.779552\n",
       "20158  3/20/2022  23:58:00 -6.268917  106.779552\n",
       "20159  3/20/2022  23:59:00 -6.268917  106.779552\n",
       "\n",
       "[20160 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(dataset_file)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903605fd-f4c3-4fdb-a30c-06fbee1ce433",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd045ce0-b9c8-4e74-974d-a1be0ea325a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.268917</td>\n",
       "      <td>106.780112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-6.268917</td>\n",
       "      <td>106.780112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-6.268917</td>\n",
       "      <td>106.780112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-6.268917</td>\n",
       "      <td>106.780112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-6.268917</td>\n",
       "      <td>106.780112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20155</th>\n",
       "      <td>2022</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1435</td>\n",
       "      <td>-6.268917</td>\n",
       "      <td>106.779552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20156</th>\n",
       "      <td>2022</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1436</td>\n",
       "      <td>-6.268917</td>\n",
       "      <td>106.779552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20157</th>\n",
       "      <td>2022</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1437</td>\n",
       "      <td>-6.268917</td>\n",
       "      <td>106.779552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20158</th>\n",
       "      <td>2022</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1438</td>\n",
       "      <td>-6.268917</td>\n",
       "      <td>106.779552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20159</th>\n",
       "      <td>2022</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1439</td>\n",
       "      <td>-6.268917</td>\n",
       "      <td>106.779552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20160 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       year  month  day_of_week  time  latitude   longitude\n",
       "0      2022      3            0     0 -6.268917  106.780112\n",
       "1      2022      3            0     1 -6.268917  106.780112\n",
       "2      2022      3            0     2 -6.268917  106.780112\n",
       "3      2022      3            0     3 -6.268917  106.780112\n",
       "4      2022      3            0     4 -6.268917  106.780112\n",
       "...     ...    ...          ...   ...       ...         ...\n",
       "20155  2022      3            6  1435 -6.268917  106.779552\n",
       "20156  2022      3            6  1436 -6.268917  106.779552\n",
       "20157  2022      3            6  1437 -6.268917  106.779552\n",
       "20158  2022      3            6  1438 -6.268917  106.779552\n",
       "20159  2022      3            6  1439 -6.268917  106.779552\n",
       "\n",
       "[20160 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting date string to datetime\n",
    "data[\"date\"] = pd.to_datetime(data[\"date\"])\n",
    "data[\"day_of_week\"] = data[\"date\"].dt.day_of_week\n",
    "data[\"month\"] = data[\"date\"].dt.month\n",
    "data[\"year\"] = data[\"date\"].dt.year\n",
    "\n",
    "# Converting time to cumulative minute\n",
    "# source: https://stackoverflow.com/questions/17951820/convert-hhmmss-to-minutes-using-python-pandas\n",
    "# credit: Andy Hayden\n",
    "data[\"time\"] = data[\"time\"].str.split(':').apply(lambda time: int(time[0]) * 60 + int(time[1]))\n",
    "\n",
    "# Removing unused column\n",
    "del data[\"date\"]\n",
    "\n",
    "# Rearrange column\n",
    "data = data[[\"year\", \"month\", \"day_of_week\", \"time\", \"latitude\", \"longitude\"]]\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae016e8-6c0d-42ee-9878-32f824a28aab",
   "metadata": {},
   "source": [
    "## Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d18e7ac1-d994-4d93-bd4c-db17e1232d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape\n",
      "Train : (13608, 6)\n",
      "Valid : (4536, 6)\n",
      "Test  : (2016, 6)\n"
     ]
    }
   ],
   "source": [
    "def split_data(data, train_split, test_split):\n",
    "    \"\"\"Split data to train, valid, and test data\"\"\"\n",
    "    # Split train_valid data and test data\n",
    "    test_len = test_split\n",
    "    if type(test_split)==float:\n",
    "        test_len = int(test_len * len(data))\n",
    "    train_val_data, test_data = data[:-test_len], data[-test_len:]\n",
    "    \n",
    "    # Split train data and valid data\n",
    "    train_len = int(len(train_val_data) * train_split)\n",
    "    train_data, valid_data = train_val_data[:train_len], train_val_data[train_len:]\n",
    "    \n",
    "    return train_data, valid_data, test_data\n",
    "\n",
    "train_data, valid_data, test_data = split_data(data, train_split, test_split)\n",
    "\n",
    "print(\"Dataset Shape\")\n",
    "print(f'Train : {train_data.shape}')\n",
    "print(f'Valid : {valid_data.shape}')\n",
    "print(f'Test  : {test_data.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f741993-e151-4736-ba1e-42ace4653a6c",
   "metadata": {},
   "source": [
    "## Windowing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbb8b63e-2c8c-4e4f-91aa-939b614ff3da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x =  (32, 40, 6)\n",
      "y =  (32, 1, 2)\n"
     ]
    }
   ],
   "source": [
    "def windowed_dataset(data, steps_size, predicts_size, batch_size, shuffle_buffer):\n",
    "    \"\"\"Create windowed dataset\"\"\"\n",
    "    # Converting to tfds\n",
    "    wds = tf.data.Dataset.from_tensor_slices(data)\n",
    "    \n",
    "    # Data shifting\n",
    "    wds = wds.window(steps_size+predicts_size, shift=predicts_size, drop_remainder=True)\n",
    "    \n",
    "    # Flatten windows\n",
    "    wds = wds.flat_map(lambda window : window.batch(steps_size+predicts_size))\n",
    "    \n",
    "    # Create window tuples\n",
    "    wds = wds.map(lambda window: (window[:-predicts_size], window[-predicts_size:, -num_of_labels:]))\n",
    "\n",
    "    # Shuffle windows\n",
    "    wds = wds.shuffle(shuffle_buffer)\n",
    "    \n",
    "    # Batch windows\n",
    "    wds = wds.batch(batch_size).prefetch(1)\n",
    "    \n",
    "    return wds\n",
    "\n",
    "wds = windowed_dataset(data, steps_size, predicts_size, batch_size, shuffle_buffer_size)\n",
    "for idx,(x,y) in enumerate(wds):\n",
    "    print(\"x = \", x.numpy().shape)\n",
    "    print(\"y = \", y.numpy().shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "689d4451-2ffc-4624-ac67-a43f0e8f152c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x =  (32, 40, 6)\n",
      "y =  (32, 1, 2)\n",
      "(TensorSpec(shape=(None, None, 6), dtype=tf.float64, name=None), TensorSpec(shape=(None, None, 2), dtype=tf.float64, name=None))\n"
     ]
    }
   ],
   "source": [
    "train_wds = windowed_dataset(train_data, steps_size, predicts_size, batch_size, shuffle_buffer_size)\n",
    "for idx,(x,y) in enumerate(train_wds):\n",
    "    print(\"x = \", x.numpy().shape)\n",
    "    print(\"y = \", y.numpy().shape)\n",
    "    break\n",
    "print(train_wds.element_spec)\n",
    "\n",
    "valid_wds = windowed_dataset(valid_data, steps_size, predicts_size, batch_size, shuffle_buffer_size)\n",
    "test_wds = windowed_dataset(test_data, steps_size, predicts_size, batch_size, shuffle_buffer_size)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3737d5-7226-4a3e-85a7-0c42c0147134",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72f7ab93-954b-4f7b-af29-5de1697b7ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 40, 32)            4992      \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 16)                3136      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 16)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                272       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,554\n",
      "Trainable params: 8,554\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_model():\n",
    "    \"\"\"Create Forecasting Model\n",
    "    Model used: LSTM\n",
    "    output should consist of 2 item, latitude and longitude\n",
    "    \"\"\"\n",
    "    tf.keras.backend.clear_session()\n",
    "    # Generating model\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.LSTM(32, activation='relu', input_shape=(steps_size, num_of_features), return_sequences=True),\n",
    "        tf.keras.layers.LSTM(16, activation='relu'),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(16, activation='linear'),\n",
    "        tf.keras.layers.Dense(8, activation='sigmoid'),\n",
    "        tf.keras.layers.Dense(num_of_labels, activation='linear')\n",
    "    ])\n",
    "\n",
    "    # Compiling model\n",
    "    model.compile(\n",
    "        loss=loss,\n",
    "        optimizer=optimizer,\n",
    "        metrics=metrics,\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "371563be-a495-4827-8b85-b96fafb969e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "424/424 [==============================] - 18s 35ms/step - loss: 21.6409 - mae: 21.9096 - mse: 1548.7006 - val_loss: 0.0374 - val_mae: 0.0830 - val_mse: 1.2671\n",
      "Epoch 2/20\n",
      "424/424 [==============================] - 14s 33ms/step - loss: 0.0618 - mae: 0.1066 - mse: 1.5416 - val_loss: 0.0369 - val_mae: 0.0756 - val_mse: 1.2519\n",
      "Epoch 3/20\n",
      "424/424 [==============================] - 14s 34ms/step - loss: 0.0630 - mae: 0.1089 - mse: 1.5202 - val_loss: 0.0367 - val_mae: 0.0778 - val_mse: 1.2300\n",
      "Epoch 4/20\n",
      "424/424 [==============================] - 14s 33ms/step - loss: 0.0615 - mae: 0.1036 - mse: 1.4866 - val_loss: 0.0362 - val_mae: 0.0740 - val_mse: 1.2005\n",
      "Epoch 5/20\n",
      "424/424 [==============================] - 15s 35ms/step - loss: 0.0622 - mae: 0.1047 - mse: 1.4497 - val_loss: 0.0358 - val_mae: 0.0721 - val_mse: 1.1647\n",
      "Epoch 6/20\n",
      "424/424 [==============================] - 15s 35ms/step - loss: 0.0624 - mae: 0.1069 - mse: 1.4044 - val_loss: 0.0354 - val_mae: 0.0709 - val_mse: 1.1198\n",
      "Epoch 7/20\n",
      "424/424 [==============================] - 15s 35ms/step - loss: 0.0627 - mae: 0.1070 - mse: 1.3520 - val_loss: 0.0349 - val_mae: 0.0704 - val_mse: 1.0681\n",
      "Epoch 8/20\n",
      "424/424 [==============================] - 15s 34ms/step - loss: 0.0610 - mae: 0.1062 - mse: 1.2797 - val_loss: 0.0342 - val_mae: 0.0687 - val_mse: 1.0082\n",
      "Epoch 9/20\n",
      "424/424 [==============================] - 15s 34ms/step - loss: 0.0604 - mae: 0.1044 - mse: 1.2029 - val_loss: 0.0333 - val_mae: 0.0595 - val_mse: 0.9410\n",
      "Epoch 10/20\n",
      "424/424 [==============================] - 15s 35ms/step - loss: 0.0609 - mae: 0.1054 - mse: 1.1196 - val_loss: 0.0325 - val_mae: 0.0586 - val_mse: 0.8678\n",
      "Epoch 11/20\n",
      "424/424 [==============================] - 15s 35ms/step - loss: 0.0592 - mae: 0.1010 - mse: 1.0319 - val_loss: 0.0317 - val_mae: 0.0578 - val_mse: 0.7902\n",
      "Epoch 12/20\n",
      "424/424 [==============================] - 15s 34ms/step - loss: 0.0595 - mae: 0.1036 - mse: 0.9407 - val_loss: 0.0310 - val_mae: 0.0607 - val_mse: 0.7113\n",
      "Epoch 13/20\n",
      "424/424 [==============================] - 15s 35ms/step - loss: 0.0576 - mae: 0.1021 - mse: 0.8397 - val_loss: 0.0299 - val_mae: 0.0568 - val_mse: 0.6332\n",
      "Epoch 14/20\n",
      "424/424 [==============================] - 15s 35ms/step - loss: 0.0568 - mae: 0.1003 - mse: 0.7496 - val_loss: 0.0290 - val_mae: 0.0569 - val_mse: 0.5612\n",
      "Epoch 15/20\n",
      "424/424 [==============================] - 15s 34ms/step - loss: 0.0539 - mae: 0.0962 - mse: 0.6605 - val_loss: 0.0279 - val_mae: 0.0550 - val_mse: 0.4964\n",
      "Epoch 16/20\n",
      "424/424 [==============================] - 15s 35ms/step - loss: 0.0511 - mae: 0.0923 - mse: 0.5817 - val_loss: 0.0267 - val_mae: 0.0511 - val_mse: 0.4428\n",
      "Epoch 17/20\n",
      "424/424 [==============================] - 16s 38ms/step - loss: 0.0498 - mae: 0.0906 - mse: 0.5188 - val_loss: 0.0256 - val_mae: 0.0517 - val_mse: 0.4038\n",
      "Epoch 18/20\n",
      "424/424 [==============================] - 17s 39ms/step - loss: 0.0492 - mae: 0.0911 - mse: 0.4776 - val_loss: 0.0246 - val_mae: 0.0582 - val_mse: 0.3825\n",
      "Epoch 19/20\n",
      "424/424 [==============================] - 15s 35ms/step - loss: 0.0490 - mae: 0.0927 - mse: 0.4520 - val_loss: 0.0232 - val_mae: 0.0493 - val_mse: 0.3783\n",
      "Epoch 20/20\n",
      "424/424 [==============================] - 15s 35ms/step - loss: 0.0466 - mae: 0.0892 - mse: 0.4459 - val_loss: 0.0220 - val_mae: 0.0480 - val_mse: 0.3943\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20b280951c0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_wds, epochs=20, validation_data=valid_wds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f8dd2f1-26a3-4bbd-9950-54455af14fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0228 - mae: 0.0580 - mse: 0.4285\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.02281029522418976, 0.05797765776515007, 0.42852047085762024]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_wds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0dbd3560-e268-48a4-a8f5-963dc55064ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=(None, None, 6), dtype=tf.float64, name=None), TensorSpec(shape=(None, None, 2), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_wds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b267a771-a5eb-48e9-8665-143e0771148a",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4837386c-c607-421c-a0fb-36d8cb4911da",
   "metadata": {},
   "source": [
    "- [Sequences, Time Series and Prediction by DeepLearning.AI](https://www.coursera.org/learn/tensorflow-sequences-time-series-and-prediction)\n",
    "- [Multi-Variate Time Series Forecasting Tensorflow by Nicholas Jhana](https://www.kaggle.com/code/nicholasjhana/multi-variate-time-series-forecasting-tensorflow/notebook#Visualizing-Predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
