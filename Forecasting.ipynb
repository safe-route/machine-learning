{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "840aa704-6ca0-4fe9-af7a-e0c1d0e889ff",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d371c76a-f6f5-4d71-82f4-df7888d8107a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# # Utils\n",
    "# from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9d61ec-65bf-4370-aef3-b443dacf8410",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b989cef0-7d2b-4442-b155-e829007420ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "learning_rate = 5e-2\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "loss = tf.keras.losses.Huber()\n",
    "metrics = [\"mae\", \"mse\"]\n",
    "epochs = 1000\n",
    "\n",
    "# Data split\n",
    "test_split = 0.1                # Float or int\n",
    "valid_split = 0.1               # Float\n",
    "train_split = 1 - valid_split   # Float\n",
    "\n",
    "# Dataset window\n",
    "steps_size = 15               # minutes\n",
    "predicts_size = 1             # minute(s)\n",
    "window_size = steps_size + predicts_size\n",
    "batch_size = 32\n",
    "shuffle_buffer_size = 64\n",
    "\n",
    "# Dataset frame\n",
    "num_of_features = 6\n",
    "num_of_labels = 2\n",
    "\n",
    "# File\n",
    "dataset_file = './dataset/user_1/user_1_data.csv'\n",
    "model_1_file = './model/user_1/'\n",
    "model_2_file = './model/...'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8c65a6-31c7-4a6a-acaf-d061b6a43b73",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920ee007-c846-4910-919e-24935b1f5c34",
   "metadata": {},
   "source": [
    "## Fetching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b43bc0c-4536-4c9a-91e1-57d17bd259ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3/7/2022</td>\n",
       "      <td>0:00:00</td>\n",
       "      <td>-6.268917</td>\n",
       "      <td>106.780112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3/7/2022</td>\n",
       "      <td>0:01:00</td>\n",
       "      <td>-6.268917</td>\n",
       "      <td>106.780112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3/7/2022</td>\n",
       "      <td>0:02:00</td>\n",
       "      <td>-6.268917</td>\n",
       "      <td>106.780112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3/7/2022</td>\n",
       "      <td>0:03:00</td>\n",
       "      <td>-6.268917</td>\n",
       "      <td>106.780112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3/7/2022</td>\n",
       "      <td>0:04:00</td>\n",
       "      <td>-6.268917</td>\n",
       "      <td>106.780112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20155</th>\n",
       "      <td>3/20/2022</td>\n",
       "      <td>23:55:00</td>\n",
       "      <td>-6.268917</td>\n",
       "      <td>106.779552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20156</th>\n",
       "      <td>3/20/2022</td>\n",
       "      <td>23:56:00</td>\n",
       "      <td>-6.268917</td>\n",
       "      <td>106.779552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20157</th>\n",
       "      <td>3/20/2022</td>\n",
       "      <td>23:57:00</td>\n",
       "      <td>-6.268917</td>\n",
       "      <td>106.779552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20158</th>\n",
       "      <td>3/20/2022</td>\n",
       "      <td>23:58:00</td>\n",
       "      <td>-6.268917</td>\n",
       "      <td>106.779552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20159</th>\n",
       "      <td>3/20/2022</td>\n",
       "      <td>23:59:00</td>\n",
       "      <td>-6.268917</td>\n",
       "      <td>106.779552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20160 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date      time  latitude   longitude\n",
       "0       3/7/2022   0:00:00 -6.268917  106.780112\n",
       "1       3/7/2022   0:01:00 -6.268917  106.780112\n",
       "2       3/7/2022   0:02:00 -6.268917  106.780112\n",
       "3       3/7/2022   0:03:00 -6.268917  106.780112\n",
       "4       3/7/2022   0:04:00 -6.268917  106.780112\n",
       "...          ...       ...       ...         ...\n",
       "20155  3/20/2022  23:55:00 -6.268917  106.779552\n",
       "20156  3/20/2022  23:56:00 -6.268917  106.779552\n",
       "20157  3/20/2022  23:57:00 -6.268917  106.779552\n",
       "20158  3/20/2022  23:58:00 -6.268917  106.779552\n",
       "20159  3/20/2022  23:59:00 -6.268917  106.779552\n",
       "\n",
       "[20160 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(dataset_file)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903605fd-f4c3-4fdb-a30c-06fbee1ce433",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd045ce0-b9c8-4e74-974d-a1be0ea325a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.268917</td>\n",
       "      <td>106.780112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-6.268917</td>\n",
       "      <td>106.780112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-6.268917</td>\n",
       "      <td>106.780112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-6.268917</td>\n",
       "      <td>106.780112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-6.268917</td>\n",
       "      <td>106.780112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20155</th>\n",
       "      <td>2022</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1435</td>\n",
       "      <td>-6.268917</td>\n",
       "      <td>106.779552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20156</th>\n",
       "      <td>2022</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1436</td>\n",
       "      <td>-6.268917</td>\n",
       "      <td>106.779552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20157</th>\n",
       "      <td>2022</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1437</td>\n",
       "      <td>-6.268917</td>\n",
       "      <td>106.779552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20158</th>\n",
       "      <td>2022</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1438</td>\n",
       "      <td>-6.268917</td>\n",
       "      <td>106.779552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20159</th>\n",
       "      <td>2022</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1439</td>\n",
       "      <td>-6.268917</td>\n",
       "      <td>106.779552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20160 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       year  month  day_of_week  time  latitude   longitude\n",
       "0      2022      3            0     0 -6.268917  106.780112\n",
       "1      2022      3            0     1 -6.268917  106.780112\n",
       "2      2022      3            0     2 -6.268917  106.780112\n",
       "3      2022      3            0     3 -6.268917  106.780112\n",
       "4      2022      3            0     4 -6.268917  106.780112\n",
       "...     ...    ...          ...   ...       ...         ...\n",
       "20155  2022      3            6  1435 -6.268917  106.779552\n",
       "20156  2022      3            6  1436 -6.268917  106.779552\n",
       "20157  2022      3            6  1437 -6.268917  106.779552\n",
       "20158  2022      3            6  1438 -6.268917  106.779552\n",
       "20159  2022      3            6  1439 -6.268917  106.779552\n",
       "\n",
       "[20160 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting date string to datetime\n",
    "data[\"date\"] = pd.to_datetime(data[\"date\"])\n",
    "data[\"day_of_week\"] = data[\"date\"].dt.day_of_week\n",
    "data[\"month\"] = data[\"date\"].dt.month\n",
    "data[\"year\"] = data[\"date\"].dt.year\n",
    "\n",
    "# Converting time to cumulative minute\n",
    "# source: https://stackoverflow.com/questions/17951820/convert-hhmmss-to-minutes-using-python-pandas\n",
    "# credit: Andy Hayden\n",
    "data[\"time\"] = data[\"time\"].str.split(':').apply(lambda time: int(time[0]) * 60 + int(time[1]))\n",
    "\n",
    "# Removing unused column\n",
    "del data[\"date\"]\n",
    "\n",
    "# Rearrange column\n",
    "data = data[[\"year\", \"month\", \"day_of_week\", \"time\", \"latitude\", \"longitude\"]]\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae016e8-6c0d-42ee-9878-32f824a28aab",
   "metadata": {},
   "source": [
    "## Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d18e7ac1-d994-4d93-bd4c-db17e1232d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape\n",
      "Train : (16329, 6)\n",
      "Valid : (1815, 6)\n",
      "Test  : (2016, 6)\n"
     ]
    }
   ],
   "source": [
    "def split_data(data, train_split, test_split):\n",
    "    \"\"\"Split data to train, valid, and test data\"\"\"\n",
    "    # Split train_valid data and test data\n",
    "    test_len = test_split\n",
    "    if type(test_split)==float:\n",
    "        test_len = int(test_len * len(data))\n",
    "    train_val_data, test_data = data[:-test_len], data[-test_len:]\n",
    "    \n",
    "    # Split train data and valid data\n",
    "    train_len = int(len(train_val_data) * train_split)\n",
    "    train_data, valid_data = train_val_data[:train_len], train_val_data[train_len:]\n",
    "    \n",
    "    return train_data, valid_data, test_data\n",
    "\n",
    "train_data, valid_data, test_data = split_data(data, train_split, test_split)\n",
    "\n",
    "print(\"Dataset Shape\")\n",
    "print(f'Train : {train_data.shape}')\n",
    "print(f'Valid : {valid_data.shape}')\n",
    "print(f'Test  : {test_data.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f741993-e151-4736-ba1e-42ace4653a6c",
   "metadata": {},
   "source": [
    "## Windowing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbb8b63e-2c8c-4e4f-91aa-939b614ff3da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x =  (32, 15, 6)\n",
      "y =  (32, 1, 2)\n"
     ]
    }
   ],
   "source": [
    "def windowed_dataset(data, steps_size, predicts_size, batch_size, shuffle_buffer):\n",
    "    \"\"\"Create windowed dataset\"\"\"\n",
    "    # Converting to tfds\n",
    "    wds = tf.data.Dataset.from_tensor_slices(data)\n",
    "    \n",
    "    # Data shifting\n",
    "    wds = wds.window(steps_size+predicts_size, shift=predicts_size, drop_remainder=True)\n",
    "    \n",
    "    # Flatten windows\n",
    "    wds = wds.flat_map(lambda window : window.batch(steps_size+predicts_size))\n",
    "    \n",
    "    # Create window tuples\n",
    "    wds = wds.map(lambda window: (window[:-predicts_size], window[-predicts_size:, -num_of_labels:]))\n",
    "    \n",
    "    # Shuffle windows\n",
    "    wds = wds.shuffle(shuffle_buffer)\n",
    "    \n",
    "    # Batch windows\n",
    "    wds = wds.batch(batch_size).prefetch(1)\n",
    "    \n",
    "    return wds\n",
    "\n",
    "wds = windowed_dataset(data, steps_size, predicts_size, batch_size, shuffle_buffer_size)\n",
    "for idx,(x,y) in enumerate(wds):\n",
    "    print(\"x = \", x.numpy().shape)\n",
    "    print(\"y = \", y.numpy().shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "689d4451-2ffc-4624-ac67-a43f0e8f152c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_wds = windowed_dataset(train_data, steps_size, predicts_size, batch_size, shuffle_buffer_size)\n",
    "valid_wds = windowed_dataset(valid_data, steps_size, predicts_size, batch_size, shuffle_buffer_size)\n",
    "test_wds = windowed_dataset(test_data, steps_size, predicts_size, batch_size, shuffle_buffer_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3737d5-7226-4a3e-85a7-0c42c0147134",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f5b562-71ae-41af-b98d-f1e495480172",
   "metadata": {},
   "source": [
    "## Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "72f7ab93-954b-4f7b-af29-5de1697b7ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 15, 64)            18176     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 15, 32)            12416     \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 16)                3136      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 16)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                272       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34,154\n",
      "Trainable params: 34,154\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_model():\n",
    "    \"\"\"Create Forecasting Model\n",
    "    Model used: LSTM\n",
    "    output should consist of 2 item, latitude and longitude\n",
    "    \"\"\"\n",
    "    tf.keras.backend.clear_session()\n",
    "    # Generating model\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.LSTM(64, activation='sigmoid', input_shape=(steps_size, num_of_features), return_sequences=True),\n",
    "        tf.keras.layers.LSTM(32, activation='sigmoid', return_sequences=True),\n",
    "        tf.keras.layers.LSTM(16, activation='sigmoid'),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(16, activation='sigmoid'),\n",
    "        tf.keras.layers.Dense(8, activation='sigmoid'),\n",
    "        tf.keras.layers.Dense(num_of_labels, activation='linear')\n",
    "    ])\n",
    "\n",
    "    # Compiling model\n",
    "    model.compile(\n",
    "        loss=loss,\n",
    "        optimizer=optimizer,\n",
    "        metrics=metrics,\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc392864-8bf9-4537-b844-d553821aac28",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "371563be-a495-4827-8b85-b96fafb969e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "510/510 [==============================] - 11s 16ms/step - loss: 2.4387 - mae: 2.5161 - mse: 171.5694 - val_loss: 7.3463e-04 - val_mae: 0.0320 - val_mse: 0.0015\n",
      "Epoch 2/20\n",
      "510/510 [==============================] - 8s 15ms/step - loss: 1.7369e-04 - mae: 0.0128 - mse: 3.4742e-04 - val_loss: 6.3544e-04 - val_mae: 0.0276 - val_mse: 0.0013\n",
      "Epoch 3/20\n",
      "510/510 [==============================] - 8s 16ms/step - loss: 1.4363e-04 - mae: 0.0111 - mse: 2.8710e-04 - val_loss: 6.1483e-04 - val_mae: 0.0267 - val_mse: 0.0012\n",
      "Epoch 4/20\n",
      "510/510 [==============================] - 8s 15ms/step - loss: 1.3278e-04 - mae: 0.0106 - mse: 2.6558e-04 - val_loss: 6.2296e-04 - val_mae: 0.0265 - val_mse: 0.0012\n",
      "Epoch 5/20\n",
      "510/510 [==============================] - 9s 17ms/step - loss: 1.2567e-04 - mae: 0.0100 - mse: 2.5122e-04 - val_loss: 6.7220e-04 - val_mae: 0.0287 - val_mse: 0.0013\n",
      "Epoch 6/20\n",
      "510/510 [==============================] - 9s 17ms/step - loss: 1.3820e-04 - mae: 0.0105 - mse: 2.7633e-04 - val_loss: 6.2457e-04 - val_mae: 0.0262 - val_mse: 0.0013\n",
      "Epoch 7/20\n",
      "510/510 [==============================] - 8s 15ms/step - loss: 1.1295e-04 - mae: 0.0097 - mse: 2.2589e-04 - val_loss: 5.8109e-04 - val_mae: 0.0234 - val_mse: 0.0012\n",
      "Epoch 8/20\n",
      "510/510 [==============================] - 8s 16ms/step - loss: 1.1297e-04 - mae: 0.0098 - mse: 2.2594e-04 - val_loss: 5.4474e-04 - val_mae: 0.0228 - val_mse: 0.0011\n",
      "Epoch 9/20\n",
      "510/510 [==============================] - 8s 16ms/step - loss: 1.0826e-04 - mae: 0.0090 - mse: 2.1651e-04 - val_loss: 4.9537e-04 - val_mae: 0.0216 - val_mse: 9.9397e-04\n",
      "Epoch 10/20\n",
      "510/510 [==============================] - 9s 18ms/step - loss: 1.3100e-04 - mae: 0.0102 - mse: 2.6200e-04 - val_loss: 4.8300e-04 - val_mae: 0.0217 - val_mse: 9.6879e-04\n",
      "Epoch 11/20\n",
      "510/510 [==============================] - 9s 18ms/step - loss: 1.5488e-04 - mae: 0.0104 - mse: 3.0974e-04 - val_loss: 5.1787e-04 - val_mae: 0.0222 - val_mse: 0.0010\n",
      "Epoch 12/20\n",
      "510/510 [==============================] - 9s 18ms/step - loss: 1.1959e-04 - mae: 0.0102 - mse: 2.3918e-04 - val_loss: 5.1148e-04 - val_mae: 0.0223 - val_mse: 0.0010\n",
      "Epoch 13/20\n",
      "510/510 [==============================] - 9s 18ms/step - loss: 1.4022e-04 - mae: 0.0109 - mse: 2.8047e-04 - val_loss: 5.3112e-04 - val_mae: 0.0225 - val_mse: 0.0011\n",
      "Epoch 14/20\n",
      "510/510 [==============================] - 9s 18ms/step - loss: 1.2003e-04 - mae: 0.0107 - mse: 2.4000e-04 - val_loss: 4.8258e-04 - val_mae: 0.0213 - val_mse: 9.6746e-04\n",
      "Epoch 15/20\n",
      "510/510 [==============================] - 10s 20ms/step - loss: 1.9456e-04 - mae: 0.0130 - mse: 3.8913e-04 - val_loss: 5.6636e-04 - val_mae: 0.0244 - val_mse: 0.0011\n",
      "Epoch 16/20\n",
      "510/510 [==============================] - 9s 17ms/step - loss: 1.4683e-04 - mae: 0.0118 - mse: 2.9364e-04 - val_loss: 4.9679e-04 - val_mae: 0.0221 - val_mse: 9.9660e-04\n",
      "Epoch 17/20\n",
      "510/510 [==============================] - 10s 19ms/step - loss: 1.5128e-04 - mae: 0.0119 - mse: 3.0249e-04 - val_loss: 4.8537e-04 - val_mae: 0.0218 - val_mse: 9.7336e-04\n",
      "Epoch 18/20\n",
      "510/510 [==============================] - 9s 18ms/step - loss: 1.6676e-04 - mae: 0.0125 - mse: 3.3352e-04 - val_loss: 4.9051e-04 - val_mae: 0.0218 - val_mse: 9.8414e-04\n",
      "Epoch 19/20\n",
      "510/510 [==============================] - 9s 18ms/step - loss: 1.8466e-04 - mae: 0.0127 - mse: 3.6931e-04 - val_loss: 7.0107e-04 - val_mae: 0.0242 - val_mse: 0.0014\n",
      "Epoch 20/20\n",
      "510/510 [==============================] - 10s 19ms/step - loss: 1.5457e-04 - mae: 0.0118 - mse: 3.0914e-04 - val_loss: 6.1369e-04 - val_mae: 0.0264 - val_mse: 0.0012\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b4a492a220>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_wds, epochs=20, validation_data=valid_wds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76cb9a6-3289-49fd-908f-1766da1f383d",
   "metadata": {},
   "source": [
    "## Evaluating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0f8dd2f1-26a3-4bbd-9950-54455af14fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 6ms/step - loss: 9.3190e-04 - mae: 0.0359 - mse: 0.0019\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0009318969678133726, 0.035878490656614304, 0.0018645442323759198]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_wds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f684fc8-ec1d-4857-966f-4ec348c2da01",
   "metadata": {},
   "source": [
    "## Using Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad6cff7-8512-4fe4-a188-a4ee4178a943",
   "metadata": {},
   "source": [
    "### Converting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0dbd3560-e268-48a4-a8f5-963dc55064ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=(None, None, 6), dtype=tf.float64, name=None), TensorSpec(shape=(None, None, 2), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_data(data):\n",
    "    \"\"\"Convert data to model input\"\"\"\n",
    "    # Take last \"steps size\" data from copy data\n",
    "    cdata = data.copy()[-steps_size:]\n",
    "    if len(cdata) != steps_size:\n",
    "        # Not enough data to do prediction\n",
    "        return None\n",
    "    # Add empty row in the bottom\n",
    "    cdata.loc[cdata.shape[0]] = np.zeros(num_of_features)\n",
    "    \n",
    "    return windowed_dataset(cdata, steps_size, predicts_size, batch_size, shuffle_buffer_size)\n",
    "\n",
    "predict_data = convert_data(data)\n",
    "predict_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e57bfa-f570-4ded-9315-bd4565effe0d",
   "metadata": {},
   "source": [
    "### Predicting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "af3bbc2f-6ce9-47f9-9f14-03481e7b9b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "========================================\n",
      "Predict\n",
      "========================================\n",
      "\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "[[ -6.2238636 106.81572  ]]\n",
      "\n",
      "\n",
      "========================================\n",
      "Label\n",
      "========================================\n",
      "\n",
      "[[-6.229087622, 106.7979363]]\n"
     ]
    }
   ],
   "source": [
    "def predict(model, data):\n",
    "    \"\"\"Predict data using model and data\"\"\"\n",
    "    steps_data = convert_data(data)\n",
    "    if not steps_data:\n",
    "        # If converting failed (not enough data) return none\n",
    "        return None\n",
    "    # Else return prediction\n",
    "    return  model.predict(\n",
    "        steps_data\n",
    "    )\n",
    "\n",
    "\n",
    "print(\"\\n\\n========================================\")\n",
    "print(\"Predict\")\n",
    "print(\"========================================\\n\")\n",
    "print(predict(model, data[:6763]))\n",
    "\n",
    "print(\"\\n\\n========================================\")\n",
    "print(\"Label\")\n",
    "print(\"========================================\\n\")\n",
    "print([[data.loc[6763][\"latitude\"], data.loc[6763][\"longitude\"]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b267a771-a5eb-48e9-8665-143e0771148a",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4837386c-c607-421c-a0fb-36d8cb4911da",
   "metadata": {},
   "source": [
    "- [Sequences, Time Series and Prediction by DeepLearning.AI](https://www.coursera.org/learn/tensorflow-sequences-time-series-and-prediction)\n",
    "- [Multi-Variate Time Series Forecasting Tensorflow by Nicholas Jhana](https://www.kaggle.com/code/nicholasjhana/multi-variate-time-series-forecasting-tensorflow/notebook#Visualizing-Predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
